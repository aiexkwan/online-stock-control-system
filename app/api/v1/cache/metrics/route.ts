/**
 * ç·©å­˜å’Œæ€§èƒ½æŒ‡æ¨™ API ç«¯é»
 * Phase 2.1 æ›´æ–° - æ™ºèƒ½ç·©å­˜é©é…å™¨æ”¯æ´
 * å°ˆå®¶å„ªåŒ–ï¼šç›£æ§ç·©å­˜æ€§èƒ½å’Œç³»çµ±å¥åº·
 */

import { getWarehouseCacheService } from '@/lib/services/warehouse-cache-service';
import { getCacheAdapter, getCurrentCacheType } from '@/lib/cache/cache-factory';
import { NextResponse } from 'next/server';

/**
 * ç²å–ç·©å­˜æ€§èƒ½æŒ‡æ¨™ (æ™ºèƒ½ç·©å­˜é©é…å™¨)
 */
export async function GET() {
  const startTime = Date.now();

  try {
    const warehouseService = getWarehouseCacheService();
    const cacheAdapter = getCacheAdapter();
    const cacheType = getCurrentCacheType();

    // ä¸¦è¡Œç²å–å„ç¨®æŒ‡æ¨™
    const [cacheMetrics, cacheStats, adapterMetrics, isCacheConnected] = await Promise.all([
      warehouseService.getCacheMetrics(),
      cacheAdapter.getStats(),
      cacheAdapter.getMetrics(),
      cacheAdapter.ping(),
    ]);

    const responseTime = Date.now() - startTime;

    return NextResponse.json({
      status: 'healthy',
      timestamp: new Date().toISOString(),
      responseTime: `${responseTime}ms`,
      version: 'v2.1-phase2-adaptive', // Phase 2.1 ç‰ˆæœ¬æ¨™è­˜

      // ç·©å­˜é¡å‹å’Œç‹€æ…‹ (Phase 2.1 æ–°å¢)
      cacheType: cacheType,
      cache: {
        type: cacheType,
        connected: isCacheConnected,
        memory: cacheStats.memory,
        connections: cacheStats.connections,
        operations: cacheStats.operations,
        hitRate: cacheStats.hitRate || 0,
      },

      // ç·©å­˜æ€§èƒ½æŒ‡æ¨™
      performance: {
        hits: adapterMetrics.hits,
        misses: adapterMetrics.misses,
        totalRequests: adapterMetrics.totalRequests,
        hitRate: adapterMetrics.hitRate.toFixed(2) + '%',
        avgResponseTime: adapterMetrics.avgResponseTime.toFixed(2) + 'ms',
        errorRate:
          adapterMetrics.errors > 0
            ? ((adapterMetrics.errors / adapterMetrics.totalRequests) * 100).toFixed(2) + '%'
            : '0%',
      },

      // ç³»çµ±å¥åº·æŒ‡æ¨™
      health: {
        cache: isCacheConnected ? 'healthy' : 'error',
        lastError: adapterMetrics.lastError,
        lastErrorTime: adapterMetrics.lastErrorTime,
        uptime: process.uptime(),
        memoryUsage: process.memoryUsage(),
      },

      // Phase 2.1: é©æ‡‰æ€§ç·©å­˜å„ªåŒ–å»ºè­°
      recommendations: generateAdaptiveCacheRecommendations(
        adapterMetrics as unknown as Record<string, unknown>,
        cacheStats as unknown as Record<string, unknown>,
        cacheType
      ),
    });
  } catch (error) {
    const responseTime = Date.now() - startTime;
    console.error('Cache metrics API error:', error);

    return NextResponse.json(
      {
        status: 'error',
        timestamp: new Date().toISOString(),
        responseTime: `${responseTime}ms`,
        error: error instanceof Error ? (error as { message: string }).message : 'Unknown error',
        message: 'Failed to retrieve cache metrics',
      },
      {
        status: 500,
      }
    );
  }
}

/**
 * æ¸…é™¤æŒ‡å®šçš„ç·©å­˜ (é–‹ç™¼/ç®¡ç†ç”¨é€”) - æ™ºèƒ½ç·©å­˜é©é…å™¨æ”¯æ´
 */
export async function DELETE(request: Request, { params }: { params: Promise<{ id: string }> }) {
  try {
    const { searchParams } = new URL(request.url);
    const type = searchParams.get('type') as 'summary' | 'dashboard' | 'inventory' | 'all';
    const pattern = searchParams.get('pattern');

    const warehouseService = getWarehouseCacheService();
    const cacheAdapter = getCacheAdapter();
    const cacheType = getCurrentCacheType();

    if (pattern) {
      // æ ¹æ“šæ¨¡å¼æ¸…é™¤ç·©å­˜
      const invalidatedCount = await cacheAdapter.invalidatePattern(pattern);

      return NextResponse.json({
        status: 'success',
        message: `Invalidated ${invalidatedCount} cache entries matching pattern: ${pattern}`,
        cacheType,
        timestamp: new Date().toISOString(),
      });
    } else if (type) {
      // æ ¹æ“šé¡å‹æ¸…é™¤ç·©å­˜
      await warehouseService.invalidateWarehouseCache(type);

      return NextResponse.json({
        status: 'success',
        message: `Invalidated ${type} cache`,
        cacheType,
        timestamp: new Date().toISOString(),
      });
    } else {
      // æ¸…é™¤æ‰€æœ‰ç·©å­˜
      await cacheAdapter.clear();

      return NextResponse.json({
        status: 'success',
        message: `All cache cleared (${cacheType} adapter)`,
        cacheType,
        timestamp: new Date().toISOString(),
      });
    }
  } catch (error) {
    console.error('Cache clear API error:', error);

    return NextResponse.json(
      {
        status: 'error',
        error: error instanceof Error ? (error as { message: string }).message : 'Unknown error',
        message: 'Failed to clear cache',
      },
      {
        status: 500,
      }
    );
  }
}

/**
 * é ç†±ç·©å­˜ (ç®¡ç†ç”¨é€”)
 */
export async function POST() {
  try {
    const warehouseService = getWarehouseCacheService();

    // é ç†±é—œéµç·©å­˜
    await warehouseService.preWarmCache();

    return NextResponse.json({
      status: 'success',
      message: 'Cache pre-warming completed',
      timestamp: new Date().toISOString(),
    });
  } catch (error) {
    console.error('Cache pre-warm API error:', error);

    return NextResponse.json(
      {
        status: 'error',
        error: error instanceof Error ? (error as { message: string }).message : 'Unknown error',
        message: 'Failed to pre-warm cache',
      },
      {
        status: 500,
      }
    );
  }
}

/**
 * Phase 2.1: ç”Ÿæˆé©æ‡‰æ€§ç·©å­˜å„ªåŒ–å»ºè­°
 * æ”¯æ´ Redis å’Œ Memory ç·©å­˜çš„æ™ºèƒ½åˆ†æ
 */
function generateAdaptiveCacheRecommendations(
  metrics: Record<string, unknown>,
  stats: Record<string, unknown>,
  cacheType: string
): string[] {
  const recommendations = [];

  // å‘½ä¸­ç‡å»ºè­° (é€šç”¨)
  const hitRate = typeof metrics.hitRate === 'number' ? metrics.hitRate : 0;
  if (hitRate < 70) {
    recommendations.push(
      `Cache hit rate is below 70% (${cacheType} cache). Consider increasing TTL or pre-warming more data.`
    );
  } else if (hitRate > 95) {
    recommendations.push(
      `Excellent cache hit rate with ${cacheType} cache! Consider increasing cache size.`
    );
  }

  // éŸ¿æ‡‰æ™‚é–“å»ºè­° (é©æ‡‰æ€§)
  const avgResponseTime = typeof metrics.avgResponseTime === 'number' ? metrics.avgResponseTime : 0;
  const responseTimeThreshold = cacheType === 'memory' ? 5 : 50; // å…§å­˜ç·©å­˜æ¨™æº–æ›´åš´æ ¼

  if (avgResponseTime > responseTimeThreshold) {
    if (cacheType === 'memory') {
      recommendations.push(
        `Memory cache response time is high (${avgResponseTime.toFixed(2)}ms). Consider reducing cache size or optimizing data structures.`
      );
    } else {
      recommendations.push(
        `Redis cache response time is high (${avgResponseTime.toFixed(2)}ms). Consider optimizing Redis configuration or network latency.`
      );
    }
  }

  // éŒ¯èª¤ç‡å»ºè­° (é€šç”¨)
  const errors = typeof metrics.errors === 'number' ? metrics.errors : 0;
  if (errors > 0) {
    recommendations.push(
      `${errors} cache errors detected with ${cacheType} cache. Check connectivity and logs.`
    );
  }

  // å…§å­˜ä½¿ç”¨å»ºè­° (é©æ‡‰æ€§)
  if (typeof stats.memory === 'string') {
    if (cacheType === 'memory') {
      // å…§å­˜ç·©å­˜ç‰¹å®šå»ºè­°
      if (stats.memory.includes('KB')) {
        const memoryKB = parseFloat(stats.memory.replace('KB', ''));
        if (memoryKB > 10000) {
          // 10MB
          recommendations.push(
            'Memory cache usage is high. Consider implementing more aggressive LRU eviction or reducing TTL.'
          );
        }
      }
    } else if (cacheType === 'redis') {
      // Redis ç‰¹å®šå»ºè­°
      if (stats.memory.includes('MB')) {
        const memoryMB = parseFloat(stats.memory.replace('MB', ''));
        if (memoryMB > 100) {
          recommendations.push(
            'Redis memory usage is high. Consider implementing cache eviction policies or data compression.'
          );
        }
      }
    }
  }

  // é€£æ¥æ•¸å»ºè­° (Redis ç‰¹å®š)
  const connections = typeof stats.connections === 'number' ? stats.connections : 0;
  if (cacheType === 'redis' && connections > 50) {
    recommendations.push(
      'High number of Redis connections. Consider connection pooling optimization.'
    );
  } else if (cacheType === 'memory' && connections > 0) {
    recommendations.push(
      'Memory cache shows connection count - this may indicate configuration issues.'
    );
  }

  // Phase 2.1 ç‰¹å®šå»ºè­°
  if (cacheType === 'memory') {
    recommendations.push(
      'âœ… Using optimized memory cache - ideal for current system scale (30-40 users).'
    );
    recommendations.push(
      'ğŸš€ Memory cache eliminates network latency - expect 1-3ms response times.'
    );
  } else if (cacheType === 'redis') {
    recommendations.push(
      'âš ï¸  Consider migrating to memory cache for better performance and simplified deployment.'
    );
  }

  // ç³»çµ±å¥åº·ç¸½çµ
  if (
    recommendations.length === 0 ||
    recommendations.every(r => r.includes('âœ…') || r.includes('ğŸš€'))
  ) {
    recommendations.push(
      `ğŸ¯ Cache performance is optimal with ${cacheType} adapter. System is well-configured for current scale.`
    );
  }

  return recommendations;
}
