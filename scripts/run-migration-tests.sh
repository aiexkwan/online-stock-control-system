#!/bin/bash

##############################################################################
# GraphQL â†’ REST API é·ç§»æ¸¬è©¦åŸ·è¡Œè…³æœ¬
# QAå°ˆå®¶ - è‡ªå‹•åŒ–æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå™¨
##############################################################################

set -e

# é¡è‰²å®šç¾©
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# æ—¥èªŒå‡½æ•¸
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

# åƒæ•¸è§£æž
TEST_TYPE="${1:-all}"
ENVIRONMENT="${NODE_ENV:-test}"
PARALLEL="${2:-true}"
VERBOSE="${3:-false}"

log_info "ðŸ§ª Starting Migration Test Suite"
log_info "ðŸ“‹ Test Type: $TEST_TYPE"
log_info "ðŸŒ Environment: $ENVIRONMENT"
log_info "âš¡ Parallel: $PARALLEL"

# å‰µå»ºæ¸¬è©¦çµæžœç›®éŒ„
TIMESTAMP=$(date '+%Y-%m-%d_%H-%M-%S')
RESULTS_DIR="test-results/migration-$TIMESTAMP"
mkdir -p "$RESULTS_DIR"

# æ¸¬è©¦é…ç½®
export TEST_RESULTS_DIR="$RESULTS_DIR"
export MIGRATION_TEST_MODE="true"

# å–®å…ƒæ¸¬è©¦ - API ä¸€è‡´æ€§
run_unit_tests() {
    log_info "ðŸ”¬ Running Unit Tests (API Consistency)"
    
    npm run test -- __tests__/migration/api-consistency.test.ts \
        --coverage \
        --coverageDirectory="$RESULTS_DIR/coverage-unit" \
        --outputFile="$RESULTS_DIR/unit-results.json" \
        --verbose=$VERBOSE \
        2>&1 | tee "$RESULTS_DIR/unit-tests.log"
    
    if [ $? -eq 0 ]; then
        log_success "Unit tests passed"
        return 0
    else
        log_error "Unit tests failed"
        return 1
    fi
}

# æ•´åˆæ¸¬è©¦ - è³‡æ–™å®Œæ•´æ€§
run_integration_tests() {
    log_info "ðŸ”— Running Integration Tests (Data Integrity)"
    
    # è¨­ç½®æ¸¬è©¦è³‡æ–™åº«
    if [ "$ENVIRONMENT" != "test" ]; then
        log_warning "Setting up test database..."
        npm run db:setup:test || log_error "Failed to setup test database"
    fi
    
    npm run test:integration -- \
        --testPathPattern="migration" \
        --runInBand \
        --outputFile="$RESULTS_DIR/integration-results.json" \
        2>&1 | tee "$RESULTS_DIR/integration-tests.log"
    
    local result=$?
    
    # æ¸…ç†æ¸¬è©¦è³‡æ–™
    npm run db:cleanup:test || log_warning "Failed to cleanup test database"
    
    if [ $result -eq 0 ]; then
        log_success "Integration tests passed"
        return 0
    else
        log_error "Integration tests failed"
        return 1
    fi
}

# E2E æ¸¬è©¦ - ç”¨æˆ¶é«”é©—
run_e2e_tests() {
    log_info "ðŸŒ Running E2E Tests (User Experience)"
    
    # æª¢æŸ¥æœå‹™æ˜¯å¦é‹è¡Œ
    if ! curl -s http://localhost:3000/api/health > /dev/null; then
        log_info "Starting development server for E2E tests..."
        npm run dev &
        DEV_SERVER_PID=$!
        
        # ç­‰å¾…æœå‹™å•Ÿå‹•
        local max_wait=60
        local wait_time=0
        while ! curl -s http://localhost:3000/api/health > /dev/null && [ $wait_time -lt $max_wait ]; do
            sleep 2
            wait_time=$((wait_time + 2))
            log_info "Waiting for server... ($wait_time/${max_wait}s)"
        done
        
        if [ $wait_time -ge $max_wait ]; then
            log_error "Server failed to start within ${max_wait}s"
            return 1
        fi
    fi
    
    # åŸ·è¡Œ E2E æ¸¬è©¦
    local e2e_result=0
    if [ "$PARALLEL" = "true" ]; then
        npm run test:e2e -- e2e/migration/ \
            --reporter=html,json \
            --output-dir="$RESULTS_DIR/e2e-results" \
            2>&1 | tee "$RESULTS_DIR/e2e-tests.log"
        e2e_result=$?
    else
        npm run test:e2e -- e2e/migration/ \
            --workers=1 \
            --reporter=html,json \
            --output-dir="$RESULTS_DIR/e2e-results" \
            2>&1 | tee "$RESULTS_DIR/e2e-tests.log"
        e2e_result=$?
    fi
    
    # åœæ­¢é–‹ç™¼æœå‹™å™¨ï¼ˆå¦‚æžœæˆ‘å€‘å•Ÿå‹•äº†å®ƒï¼‰
    if [ -n "$DEV_SERVER_PID" ]; then
        kill $DEV_SERVER_PID || true
        wait $DEV_SERVER_PID 2>/dev/null || true
    fi
    
    if [ $e2e_result -eq 0 ]; then
        log_success "E2E tests passed"
        return 0
    else
        log_error "E2E tests failed"
        return 1
    fi
}

# æ€§èƒ½æ¸¬è©¦
run_performance_tests() {
    log_info "âš¡ Running Performance Tests"
    
    npm run test:perf -- \
        --config=playwright.performance.config.ts \
        --reporter=html,json \
        --output-dir="$RESULTS_DIR/performance-results" \
        2>&1 | tee "$RESULTS_DIR/performance-tests.log"
        
    if [ $? -eq 0 ]; then
        log_success "Performance tests passed"
        return 0
    else
        log_error "Performance tests failed"
        return 1
    fi
}

# å¯è¨ªå•æ€§æ¸¬è©¦
run_accessibility_tests() {
    log_info "â™¿ Running Accessibility Tests"
    
    npm run test:a11y -- e2e/a11y/ \
        --reporter=html,json \
        --output-dir="$RESULTS_DIR/a11y-results" \
        2>&1 | tee "$RESULTS_DIR/a11y-tests.log"
        
    if [ $? -eq 0 ]; then
        log_success "Accessibility tests passed"
        return 0
    else
        log_warning "Accessibility tests had issues (non-blocking)"
        return 0  # A11y å•é¡Œä¸é˜»æ“‹é·ç§»
    fi
}

# ç”Ÿæˆæ¸¬è©¦å ±å‘Š
generate_test_report() {
    log_info "ðŸ“Š Generating Test Report"
    
    local report_file="$RESULTS_DIR/migration-test-report.md"
    local overall_status="PASSED"
    
    # æª¢æŸ¥å„æ¸¬è©¦çµæžœ
    local unit_status="âŒ FAILED"
    local integration_status="âŒ FAILED" 
    local e2e_status="âŒ FAILED"
    local performance_status="âŒ FAILED"
    local a11y_status="âŒ FAILED"
    
    [ -f "$RESULTS_DIR/unit-results.json" ] && unit_status="âœ… PASSED"
    [ -f "$RESULTS_DIR/integration-results.json" ] && integration_status="âœ… PASSED"
    [ -f "$RESULTS_DIR/e2e-results/results.json" ] && e2e_status="âœ… PASSED"
    [ -f "$RESULTS_DIR/performance-results/results.json" ] && performance_status="âœ… PASSED"
    [ -f "$RESULTS_DIR/a11y-results/results.json" ] && a11y_status="âœ… PASSED"
    
    # æª¢æŸ¥æ•´é«”ç‹€æ…‹
    if [[ "$unit_status" =~ "FAILED" ]] || [[ "$integration_status" =~ "FAILED" ]] || [[ "$e2e_status" =~ "FAILED" ]]; then
        overall_status="FAILED"
    fi
    
    cat > "$report_file" << EOF
# Migration Test Report

**Timestamp**: $TIMESTAMP  
**Environment**: $ENVIRONMENT
**Test Type**: $TEST_TYPE
**Overall Status**: **$overall_status**

## Test Results Summary

| Test Suite | Status | Details |
|------------|--------|---------|
| Unit Tests (API Consistency) | $unit_status | GraphQL vs REST API validation |
| Integration Tests (Data Integrity) | $integration_status | Database and data flow validation |
| E2E Tests (User Experience) | $e2e_status | Widget functionality and interactions |
| Performance Tests | $performance_status | Response time and throughput validation |
| Accessibility Tests | $a11y_status | WCAG compliance validation |

## Key Metrics

### API Consistency
$(if [ -f "$RESULTS_DIR/unit-tests.log" ]; then
    grep -E "(tests? passed|tests? failed)" "$RESULTS_DIR/unit-tests.log" | tail -1 || echo "No metrics available"
else
    echo "No unit test results available"
fi)

### Performance Comparison
$(if [ -f "$RESULTS_DIR/performance-tests.log" ]; then
    grep -E "Performance|Duration|Response time" "$RESULTS_DIR/performance-tests.log" | head -5 || echo "No performance metrics available"
else
    echo "No performance test results available"
fi)

## Widget-Specific Results

### InventoryOrderedAnalysisWidget
- Data consistency: $(grep -q "InventoryOrderedAnalysisWidget.*passed" "$RESULTS_DIR"/*.log && echo "âœ… Passed" || echo "âŒ Failed")
- Performance: $(grep -q "inventory.*performance.*acceptable" "$RESULTS_DIR"/*.log && echo "âœ… Acceptable" || echo "âš ï¸ Needs review")
- User interaction: $(grep -q "inventory.*interaction.*working" "$RESULTS_DIR"/*.log && echo "âœ… Working" || echo "âŒ Issues detected")

### HistoryTreeV2  
- Rendering: $(grep -q "HistoryTreeV2.*rendered" "$RESULTS_DIR"/*.log && echo "âœ… Success" || echo "âŒ Failed")
- No factory errors: $(grep -q "factory.call.*error" "$RESULTS_DIR"/*.log && echo "âŒ Errors detected" || echo "âœ… Clean")
- Edit mode: $(grep -q "edit.*mode.*working" "$RESULTS_DIR"/*.log && echo "âœ… Working" || echo "âš ï¸ Not tested")

## Recommendations

$(if [ "$overall_status" = "PASSED" ]; then
cat << 'RECOMMENDATIONS'
âœ… **Migration Ready**: All critical tests passed
- Proceed with phased rollout
- Monitor performance metrics closely
- Keep rollback procedure ready

**Next Steps:**
1. Deploy to staging environment
2. Run full regression test suite  
3. Perform manual UAT
4. Schedule production deployment
RECOMMENDATIONS
else
cat << 'RECOMMENDATIONS'
âŒ **Migration Not Ready**: Critical issues detected
- Review failed test details below
- Fix identified issues before proceeding
- Re-run test suite after fixes

**Required Actions:**
1. Address all unit test failures
2. Resolve data integrity issues
3. Fix E2E test failures
4. Verify performance regressions
RECOMMENDATIONS
fi)

## Test Artifacts

- **Unit Test Results**: \`$RESULTS_DIR/unit-results.json\`
- **Integration Test Results**: \`$RESULTS_DIR/integration-results.json\`
- **E2E Test Results**: \`$RESULTS_DIR/e2e-results/\`
- **Performance Results**: \`$RESULTS_DIR/performance-results/\`
- **Test Logs**: \`$RESULTS_DIR/*.log\`

## Troubleshooting

$(if [ -f "$RESULTS_DIR/unit-tests.log" ]; then
    echo "### Unit Test Failures"
    grep -A 5 -B 5 "FAIL\|Error:" "$RESULTS_DIR/unit-tests.log" | head -20 || echo "No failures detected"
fi)

$(if [ -f "$RESULTS_DIR/e2e-tests.log" ]; then
    echo "### E2E Test Failures"  
    grep -A 5 -B 5 "âœ–\|Error:" "$RESULTS_DIR/e2e-tests.log" | head -20 || echo "No failures detected"
fi)

---
*Report generated automatically by migration test suite*
EOF

    log_success "Test report generated: $report_file"
    
    # é¡¯ç¤ºæ‘˜è¦
    log_info "ðŸ“‹ Test Summary:"
    echo "   Unit Tests: $unit_status"
    echo "   Integration: $integration_status"  
    echo "   E2E Tests: $e2e_status"
    echo "   Performance: $performance_status"
    echo "   Accessibility: $a11y_status"
    echo "   Overall: $overall_status"
}

# ä¸»åŸ·è¡Œå‡½æ•¸
main() {
    local failed_tests=()
    
    case "$TEST_TYPE" in
        "unit")
            run_unit_tests || failed_tests+=("unit")
            ;;
        "integration")
            run_integration_tests || failed_tests+=("integration")
            ;;
        "e2e")
            run_e2e_tests || failed_tests+=("e2e")
            ;;
        "performance")
            run_performance_tests || failed_tests+=("performance")
            ;;
        "accessibility"|"a11y")
            run_accessibility_tests || failed_tests+=("accessibility")
            ;;
        "all"|*)
            log_info "ðŸš€ Running Full Test Suite"
            
            run_unit_tests || failed_tests+=("unit")
            run_integration_tests || failed_tests+=("integration")
            run_e2e_tests || failed_tests+=("e2e")
            run_performance_tests || failed_tests+=("performance") 
            run_accessibility_tests || failed_tests+=("accessibility")
            ;;
    esac
    
    # ç”Ÿæˆå ±å‘Š
    generate_test_report
    
    # æª¢æŸ¥çµæžœ
    if [ ${#failed_tests[@]} -eq 0 ]; then
        log_success "ðŸŽ‰ All tests passed! Migration is ready."
        echo "ðŸ“‹ Full report: $RESULTS_DIR/migration-test-report.md"
        exit 0
    else
        log_error "âŒ Some tests failed: ${failed_tests[*]}"
        echo "ðŸ“‹ Check report for details: $RESULTS_DIR/migration-test-report.md"
        exit 1
    fi
}

# æ•ç²ä¸­æ–·ä¿¡è™Ÿ
trap 'log_error "Test execution interrupted"; exit 1' INT TERM

# åŸ·è¡Œä¸»ç¨‹åº
main "$@"